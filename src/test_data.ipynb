{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8334fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[[ 0.2235,  0.5451, -0.2314,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.2235,  0.7961,  0.2235,  ..., -0.2314, -1.0000, -1.0000],\n",
      "         [-1.0000,  0.2235,  0.2235,  ..., -1.0000, -1.0000, -0.2314],\n",
      "         ...,\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]), tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.]]), [1]), 0)\n"
     ]
    }
   ],
   "source": [
    "from amr.dataset import HybridGenomeDataset\n",
    "\n",
    "kleb = \"Klebsiella_pneumoniae_aztreonam\"\n",
    "staphy = \"Staphylococcus_aureus_cefoxitin\"\n",
    "\n",
    "k=6\n",
    "pathogen = staphy\n",
    "genes=[\"pbp4\",\"gyrA\",\"fusA\",\"dfrB\",\"rpoB\"]\n",
    "\n",
    "train_dataset = HybridGenomeDataset(\n",
    "    root_dir=\"../data/ds1\",\n",
    "    train_or_test=\"train\",\n",
    "    pathogen=pathogen,\n",
    "    genes=genes,\n",
    "    k=k\n",
    ")\n",
    "\n",
    "test_dataset = HybridGenomeDataset(\n",
    "    root_dir=\"../data/ds1\",\n",
    "    train_or_test=\"test\",\n",
    "    k=k,\n",
    "    pathogen=pathogen,\n",
    "    genes=[\"pbp4\"]\n",
    ")\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8a25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def hybrid_collate(batch):\n",
    "    images = []\n",
    "    sequences = []\n",
    "    genes = []\n",
    "    labels = []\n",
    "    \n",
    "    for (img, seq,gene), label in batch:\n",
    "        images.append(img)\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "        genes.append(gene)\n",
    "    \n",
    "    return (torch.stack(images), pad_sequence(sequences, batch_first=True),torch.tensor(genes)), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37cff650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "def get_train_val_dataloaders(val_split=0.2):\n",
    "    train_split_dataset, val_split_dataset = random_split(\n",
    "        train_dataset, [1 - val_split, val_split]\n",
    "    )\n",
    "    train_loader = DataLoader(train_split_dataset, batch_size=32, shuffle=True, collate_fn=hybrid_collate)\n",
    "    val_loader = DataLoader(val_split_dataset, batch_size=32, shuffle=True, collate_fn=hybrid_collate)\n",
    "    return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c00599bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Train Loss: 0.7544 | Train Acc: 0.5537 | Val Loss: 0.6947 | Val Acc: 0.6963\n",
      "Epoch 2/500 | Train Loss: 0.7097 | Train Acc: 0.5722 | Val Loss: 0.6919 | Val Acc: 0.6963\n",
      "Epoch 3/500 | Train Loss: 0.7070 | Train Acc: 0.6333 | Val Loss: 0.6947 | Val Acc: 0.6963\n",
      "Epoch 4/500 | Train Loss: 0.7066 | Train Acc: 0.6111 | Val Loss: 0.6901 | Val Acc: 0.6963\n",
      "Epoch 5/500 | Train Loss: 0.7190 | Train Acc: 0.5389 | Val Loss: 0.6904 | Val Acc: 0.6815\n",
      "Epoch 6/500 | Train Loss: 0.6843 | Train Acc: 0.6352 | Val Loss: 0.6854 | Val Acc: 0.6963\n",
      "Epoch 7/500 | Train Loss: 0.6923 | Train Acc: 0.6352 | Val Loss: 0.6896 | Val Acc: 0.6963\n",
      "Epoch 8/500 | Train Loss: 0.6812 | Train Acc: 0.6556 | Val Loss: 0.6878 | Val Acc: 0.6963\n",
      "Epoch 9/500 | Train Loss: 0.6892 | Train Acc: 0.6463 | Val Loss: 0.6939 | Val Acc: 0.6963\n",
      "Epoch 10/500 | Train Loss: 0.6779 | Train Acc: 0.6833 | Val Loss: 0.6956 | Val Acc: 0.6963\n",
      "Epoch 11/500 | Train Loss: 0.6920 | Train Acc: 0.6574 | Val Loss: 0.6871 | Val Acc: 0.7037\n",
      "Epoch 12/500 | Train Loss: 0.6886 | Train Acc: 0.6056 | Val Loss: 0.6853 | Val Acc: 0.6963\n",
      "Epoch 13/500 | Train Loss: 0.6781 | Train Acc: 0.6722 | Val Loss: 0.6888 | Val Acc: 0.6963\n",
      "Epoch 14/500 | Train Loss: 0.6874 | Train Acc: 0.6426 | Val Loss: 0.6876 | Val Acc: 0.6963\n",
      "Epoch 15/500 | Train Loss: 0.6783 | Train Acc: 0.6481 | Val Loss: 0.6864 | Val Acc: 0.6963\n",
      "Epoch 16/500 | Train Loss: 0.6846 | Train Acc: 0.6481 | Val Loss: 0.6867 | Val Acc: 0.6963\n",
      "Epoch 17/500 | Train Loss: 0.6849 | Train Acc: 0.6630 | Val Loss: 0.6822 | Val Acc: 0.6963\n",
      "Epoch 18/500 | Train Loss: 0.6767 | Train Acc: 0.6704 | Val Loss: 0.6834 | Val Acc: 0.6963\n",
      "Epoch 19/500 | Train Loss: 0.6731 | Train Acc: 0.6796 | Val Loss: 0.6804 | Val Acc: 0.7259\n",
      "Epoch 20/500 | Train Loss: 0.6676 | Train Acc: 0.6685 | Val Loss: 0.6793 | Val Acc: 0.6963\n",
      "Epoch 21/500 | Train Loss: 0.6613 | Train Acc: 0.6778 | Val Loss: 0.6769 | Val Acc: 0.6963\n",
      "Epoch 22/500 | Train Loss: 0.6725 | Train Acc: 0.6556 | Val Loss: 0.6761 | Val Acc: 0.7333\n",
      "Epoch 23/500 | Train Loss: 0.6805 | Train Acc: 0.6593 | Val Loss: 0.6749 | Val Acc: 0.6963\n",
      "Epoch 24/500 | Train Loss: 0.6652 | Train Acc: 0.6222 | Val Loss: 0.6792 | Val Acc: 0.7333\n",
      "Epoch 25/500 | Train Loss: 0.6903 | Train Acc: 0.6556 | Val Loss: 0.6756 | Val Acc: 0.7037\n",
      "Epoch 26/500 | Train Loss: 0.6592 | Train Acc: 0.6815 | Val Loss: 0.6761 | Val Acc: 0.7556\n",
      "Epoch 27/500 | Train Loss: 0.6563 | Train Acc: 0.6833 | Val Loss: 0.6819 | Val Acc: 0.7333\n",
      "Epoch 28/500 | Train Loss: 0.6824 | Train Acc: 0.6370 | Val Loss: 0.6747 | Val Acc: 0.7556\n",
      "Epoch 29/500 | Train Loss: 0.6684 | Train Acc: 0.6556 | Val Loss: 0.6807 | Val Acc: 0.7333\n",
      "Epoch 30/500 | Train Loss: 0.6691 | Train Acc: 0.6574 | Val Loss: 0.6767 | Val Acc: 0.7630\n",
      "Epoch 31/500 | Train Loss: 0.6731 | Train Acc: 0.6704 | Val Loss: 0.6824 | Val Acc: 0.7037\n",
      "Epoch 32/500 | Train Loss: 0.6643 | Train Acc: 0.6741 | Val Loss: 0.6846 | Val Acc: 0.6963\n",
      "Epoch 33/500 | Train Loss: 0.6776 | Train Acc: 0.6685 | Val Loss: 0.6791 | Val Acc: 0.6963\n",
      "Epoch 34/500 | Train Loss: 0.6536 | Train Acc: 0.7000 | Val Loss: 0.6706 | Val Acc: 0.7185\n",
      "Epoch 35/500 | Train Loss: 0.6556 | Train Acc: 0.6796 | Val Loss: 0.6853 | Val Acc: 0.7185\n",
      "Epoch 36/500 | Train Loss: 0.6718 | Train Acc: 0.7167 | Val Loss: 0.6813 | Val Acc: 0.7333\n",
      "Epoch 37/500 | Train Loss: 0.6445 | Train Acc: 0.7185 | Val Loss: 0.6839 | Val Acc: 0.7407\n",
      "Epoch 38/500 | Train Loss: 0.6641 | Train Acc: 0.6574 | Val Loss: 0.6801 | Val Acc: 0.7556\n",
      "Epoch 39/500 | Train Loss: 0.6718 | Train Acc: 0.6870 | Val Loss: 0.6748 | Val Acc: 0.7630\n",
      "Epoch 40/500 | Train Loss: 0.6509 | Train Acc: 0.6870 | Val Loss: 0.6660 | Val Acc: 0.7556\n",
      "Epoch 41/500 | Train Loss: 0.6475 | Train Acc: 0.6722 | Val Loss: 0.6690 | Val Acc: 0.7407\n",
      "Epoch 42/500 | Train Loss: 0.6591 | Train Acc: 0.6944 | Val Loss: 0.6558 | Val Acc: 0.7556\n",
      "Epoch 43/500 | Train Loss: 0.6661 | Train Acc: 0.6741 | Val Loss: 0.6538 | Val Acc: 0.7704\n",
      "Epoch 44/500 | Train Loss: 0.6432 | Train Acc: 0.6833 | Val Loss: 0.6772 | Val Acc: 0.7407\n",
      "Epoch 45/500 | Train Loss: 0.6481 | Train Acc: 0.7056 | Val Loss: 0.6561 | Val Acc: 0.7333\n",
      "Epoch 46/500 | Train Loss: 0.6258 | Train Acc: 0.7148 | Val Loss: 0.6491 | Val Acc: 0.7926\n",
      "Epoch 47/500 | Train Loss: 0.6528 | Train Acc: 0.6796 | Val Loss: 0.6484 | Val Acc: 0.7630\n",
      "Epoch 48/500 | Train Loss: 0.6435 | Train Acc: 0.7074 | Val Loss: 0.6547 | Val Acc: 0.7407\n",
      "Epoch 49/500 | Train Loss: 0.6332 | Train Acc: 0.6981 | Val Loss: 0.6502 | Val Acc: 0.7556\n",
      "Epoch 50/500 | Train Loss: 0.6297 | Train Acc: 0.7019 | Val Loss: 0.6374 | Val Acc: 0.7704\n",
      "Epoch 51/500 | Train Loss: 0.6141 | Train Acc: 0.7333 | Val Loss: 0.6475 | Val Acc: 0.7630\n",
      "Epoch 52/500 | Train Loss: 0.6150 | Train Acc: 0.7333 | Val Loss: 0.6317 | Val Acc: 0.7556\n",
      "Epoch 53/500 | Train Loss: 0.6236 | Train Acc: 0.7148 | Val Loss: 0.6155 | Val Acc: 0.7852\n",
      "Epoch 54/500 | Train Loss: 0.6078 | Train Acc: 0.7481 | Val Loss: 0.6198 | Val Acc: 0.7926\n",
      "Epoch 55/500 | Train Loss: 0.6019 | Train Acc: 0.7167 | Val Loss: 0.6604 | Val Acc: 0.7333\n",
      "Epoch 56/500 | Train Loss: 0.6014 | Train Acc: 0.7648 | Val Loss: 0.6444 | Val Acc: 0.7407\n",
      "Epoch 57/500 | Train Loss: 0.5822 | Train Acc: 0.7481 | Val Loss: 0.6041 | Val Acc: 0.8074\n",
      "Epoch 58/500 | Train Loss: 0.5927 | Train Acc: 0.7704 | Val Loss: 0.5889 | Val Acc: 0.7926\n",
      "Epoch 59/500 | Train Loss: 0.5759 | Train Acc: 0.7389 | Val Loss: 0.6570 | Val Acc: 0.7333\n",
      "Epoch 60/500 | Train Loss: 0.6171 | Train Acc: 0.6981 | Val Loss: 0.6554 | Val Acc: 0.7481\n",
      "Epoch 61/500 | Train Loss: 0.6031 | Train Acc: 0.7389 | Val Loss: 0.6167 | Val Acc: 0.7556\n",
      "Epoch 62/500 | Train Loss: 0.5758 | Train Acc: 0.7685 | Val Loss: 0.5960 | Val Acc: 0.7630\n",
      "Epoch 63/500 | Train Loss: 0.5624 | Train Acc: 0.7593 | Val Loss: 0.5552 | Val Acc: 0.7926\n",
      "Epoch 64/500 | Train Loss: 0.5815 | Train Acc: 0.7481 | Val Loss: 0.5677 | Val Acc: 0.8222\n",
      "Epoch 65/500 | Train Loss: 0.5703 | Train Acc: 0.7611 | Val Loss: 0.5806 | Val Acc: 0.8000\n",
      "Epoch 66/500 | Train Loss: 0.5644 | Train Acc: 0.7722 | Val Loss: 0.5650 | Val Acc: 0.7852\n",
      "Epoch 67/500 | Train Loss: 0.5285 | Train Acc: 0.8019 | Val Loss: 0.5510 | Val Acc: 0.7778\n",
      "Epoch 68/500 | Train Loss: 0.5500 | Train Acc: 0.7519 | Val Loss: 0.5811 | Val Acc: 0.7630\n",
      "Epoch 69/500 | Train Loss: 0.5385 | Train Acc: 0.7685 | Val Loss: 0.5555 | Val Acc: 0.7926\n",
      "Epoch 70/500 | Train Loss: 0.5332 | Train Acc: 0.8000 | Val Loss: 0.5930 | Val Acc: 0.7556\n",
      "Epoch 71/500 | Train Loss: 0.5196 | Train Acc: 0.8093 | Val Loss: 0.5579 | Val Acc: 0.7704\n",
      "Epoch 72/500 | Train Loss: 0.5025 | Train Acc: 0.7815 | Val Loss: 0.5086 | Val Acc: 0.7778\n",
      "Epoch 73/500 | Train Loss: 0.5176 | Train Acc: 0.7833 | Val Loss: 0.5516 | Val Acc: 0.8148\n",
      "Epoch 74/500 | Train Loss: 0.5049 | Train Acc: 0.8074 | Val Loss: 0.5308 | Val Acc: 0.8370\n",
      "Epoch 75/500 | Train Loss: 0.4811 | Train Acc: 0.8056 | Val Loss: 0.5040 | Val Acc: 0.8074\n",
      "Epoch 76/500 | Train Loss: 0.4830 | Train Acc: 0.7852 | Val Loss: 0.5195 | Val Acc: 0.8222\n",
      "Epoch 77/500 | Train Loss: 0.4984 | Train Acc: 0.7944 | Val Loss: 0.6041 | Val Acc: 0.7556\n",
      "Epoch 78/500 | Train Loss: 0.4819 | Train Acc: 0.7981 | Val Loss: 0.4887 | Val Acc: 0.8148\n",
      "Epoch 79/500 | Train Loss: 0.5034 | Train Acc: 0.7852 | Val Loss: 0.5032 | Val Acc: 0.7852\n",
      "Epoch 80/500 | Train Loss: 0.4927 | Train Acc: 0.8093 | Val Loss: 0.5511 | Val Acc: 0.7852\n",
      "Epoch 81/500 | Train Loss: 0.4637 | Train Acc: 0.8148 | Val Loss: 0.5409 | Val Acc: 0.8074\n",
      "Epoch 82/500 | Train Loss: 0.4498 | Train Acc: 0.8167 | Val Loss: 0.4859 | Val Acc: 0.8074\n",
      "Epoch 83/500 | Train Loss: 0.4565 | Train Acc: 0.8241 | Val Loss: 0.4851 | Val Acc: 0.8222\n",
      "Epoch 84/500 | Train Loss: 0.4617 | Train Acc: 0.8167 | Val Loss: 0.4619 | Val Acc: 0.7259\n",
      "Epoch 85/500 | Train Loss: 0.4617 | Train Acc: 0.8130 | Val Loss: 0.4831 | Val Acc: 0.8222\n",
      "Epoch 86/500 | Train Loss: 0.4657 | Train Acc: 0.8130 | Val Loss: 0.4910 | Val Acc: 0.8296\n",
      "Epoch 87/500 | Train Loss: 0.4596 | Train Acc: 0.8185 | Val Loss: 0.4646 | Val Acc: 0.7852\n",
      "Epoch 88/500 | Train Loss: 0.4638 | Train Acc: 0.8037 | Val Loss: 0.4888 | Val Acc: 0.7926\n",
      "Epoch 89/500 | Train Loss: 0.4348 | Train Acc: 0.8241 | Val Loss: 0.4695 | Val Acc: 0.8296\n",
      "Epoch 90/500 | Train Loss: 0.4512 | Train Acc: 0.7889 | Val Loss: 0.5543 | Val Acc: 0.8222\n",
      "Epoch 91/500 | Train Loss: 0.4264 | Train Acc: 0.8296 | Val Loss: 0.4721 | Val Acc: 0.8148\n",
      "Epoch 92/500 | Train Loss: 0.4001 | Train Acc: 0.8389 | Val Loss: 0.4581 | Val Acc: 0.8148\n",
      "Epoch 93/500 | Train Loss: 0.4452 | Train Acc: 0.8111 | Val Loss: 0.4893 | Val Acc: 0.8222\n",
      "Epoch 94/500 | Train Loss: 0.4177 | Train Acc: 0.8315 | Val Loss: 0.5389 | Val Acc: 0.8222\n",
      "Epoch 95/500 | Train Loss: 0.4407 | Train Acc: 0.8259 | Val Loss: 0.4750 | Val Acc: 0.8296\n",
      "Epoch 96/500 | Train Loss: 0.4276 | Train Acc: 0.8222 | Val Loss: 0.4922 | Val Acc: 0.8370\n",
      "Epoch 97/500 | Train Loss: 0.4012 | Train Acc: 0.8259 | Val Loss: 0.4704 | Val Acc: 0.7926\n",
      "Epoch 98/500 | Train Loss: 0.3984 | Train Acc: 0.8537 | Val Loss: 0.4450 | Val Acc: 0.7926\n",
      "Epoch 99/500 | Train Loss: 0.4127 | Train Acc: 0.8519 | Val Loss: 0.4587 | Val Acc: 0.7778\n",
      "Epoch 100/500 | Train Loss: 0.4167 | Train Acc: 0.8463 | Val Loss: 0.4499 | Val Acc: 0.7556\n",
      "Epoch 101/500 | Train Loss: 0.3900 | Train Acc: 0.8278 | Val Loss: 0.5602 | Val Acc: 0.7926\n",
      "Epoch 102/500 | Train Loss: 0.4117 | Train Acc: 0.8296 | Val Loss: 0.4577 | Val Acc: 0.8370\n",
      "Epoch 103/500 | Train Loss: 0.3971 | Train Acc: 0.8481 | Val Loss: 0.4659 | Val Acc: 0.8000\n",
      "Epoch 104/500 | Train Loss: 0.3974 | Train Acc: 0.8259 | Val Loss: 0.4441 | Val Acc: 0.8074\n",
      "Epoch 105/500 | Train Loss: 0.3966 | Train Acc: 0.8444 | Val Loss: 0.4929 | Val Acc: 0.8148\n",
      "Epoch 106/500 | Train Loss: 0.3776 | Train Acc: 0.8389 | Val Loss: 0.4659 | Val Acc: 0.7778\n",
      "Epoch 107/500 | Train Loss: 0.3686 | Train Acc: 0.8593 | Val Loss: 0.4878 | Val Acc: 0.8296\n",
      "Epoch 108/500 | Train Loss: 0.3767 | Train Acc: 0.8389 | Val Loss: 0.4675 | Val Acc: 0.8074\n",
      "Epoch 109/500 | Train Loss: 0.3849 | Train Acc: 0.8444 | Val Loss: 0.4336 | Val Acc: 0.8444\n",
      "Epoch 110/500 | Train Loss: 0.3908 | Train Acc: 0.8370 | Val Loss: 0.4183 | Val Acc: 0.8000\n",
      "Epoch 111/500 | Train Loss: 0.3689 | Train Acc: 0.8556 | Val Loss: 0.5025 | Val Acc: 0.8370\n",
      "Epoch 112/500 | Train Loss: 0.3845 | Train Acc: 0.8463 | Val Loss: 0.4964 | Val Acc: 0.8222\n",
      "Epoch 113/500 | Train Loss: 0.3787 | Train Acc: 0.8537 | Val Loss: 0.4228 | Val Acc: 0.7852\n",
      "Epoch 114/500 | Train Loss: 0.3742 | Train Acc: 0.8278 | Val Loss: 0.5334 | Val Acc: 0.8296\n",
      "Epoch 115/500 | Train Loss: 0.3692 | Train Acc: 0.8519 | Val Loss: 0.5090 | Val Acc: 0.8370\n",
      "Epoch 116/500 | Train Loss: 0.3668 | Train Acc: 0.8463 | Val Loss: 0.4877 | Val Acc: 0.8000\n",
      "Epoch 117/500 | Train Loss: 0.3554 | Train Acc: 0.8667 | Val Loss: 0.4602 | Val Acc: 0.8074\n",
      "Epoch 118/500 | Train Loss: 0.3719 | Train Acc: 0.8426 | Val Loss: 0.4494 | Val Acc: 0.8222\n",
      "Epoch 119/500 | Train Loss: 0.3532 | Train Acc: 0.8574 | Val Loss: 0.4910 | Val Acc: 0.8370\n",
      "Epoch 120/500 | Train Loss: 0.3508 | Train Acc: 0.8537 | Val Loss: 0.4875 | Val Acc: 0.8222\n",
      "Epoch 121/500 | Train Loss: 0.3617 | Train Acc: 0.8389 | Val Loss: 0.4218 | Val Acc: 0.8296\n",
      "Epoch 122/500 | Train Loss: 0.3448 | Train Acc: 0.8630 | Val Loss: 0.4443 | Val Acc: 0.8370\n",
      "Epoch 123/500 | Train Loss: 0.3551 | Train Acc: 0.8463 | Val Loss: 0.4473 | Val Acc: 0.8148\n",
      "Epoch 124/500 | Train Loss: 0.3608 | Train Acc: 0.8704 | Val Loss: 0.4249 | Val Acc: 0.8074\n",
      "Epoch 125/500 | Train Loss: 0.3592 | Train Acc: 0.8481 | Val Loss: 0.4776 | Val Acc: 0.8370\n",
      "Epoch 126/500 | Train Loss: 0.3322 | Train Acc: 0.8611 | Val Loss: 0.4609 | Val Acc: 0.8074\n",
      "Epoch 127/500 | Train Loss: 0.3487 | Train Acc: 0.8481 | Val Loss: 0.4809 | Val Acc: 0.8444\n",
      "Epoch 128/500 | Train Loss: 0.3710 | Train Acc: 0.8685 | Val Loss: 0.4509 | Val Acc: 0.8370\n",
      "Epoch 129/500 | Train Loss: 0.3440 | Train Acc: 0.8481 | Val Loss: 0.4636 | Val Acc: 0.7852\n",
      "Epoch 130/500 | Train Loss: 0.3675 | Train Acc: 0.8463 | Val Loss: 0.4349 | Val Acc: 0.8222\n",
      "Epoch 131/500 | Train Loss: 0.3355 | Train Acc: 0.8519 | Val Loss: 0.4582 | Val Acc: 0.8000\n",
      "Epoch 132/500 | Train Loss: 0.3344 | Train Acc: 0.8593 | Val Loss: 0.4768 | Val Acc: 0.8000\n",
      "Epoch 133/500 | Train Loss: 0.3139 | Train Acc: 0.8741 | Val Loss: 0.5070 | Val Acc: 0.8296\n",
      "Epoch 134/500 | Train Loss: 0.3269 | Train Acc: 0.8778 | Val Loss: 0.4803 | Val Acc: 0.8296\n",
      "Epoch 135/500 | Train Loss: 0.3462 | Train Acc: 0.8667 | Val Loss: 0.4739 | Val Acc: 0.8444\n",
      "Epoch 136/500 | Train Loss: 0.3566 | Train Acc: 0.8333 | Val Loss: 0.4937 | Val Acc: 0.7704\n",
      "Epoch 137/500 | Train Loss: 0.3183 | Train Acc: 0.8537 | Val Loss: 0.4789 | Val Acc: 0.8000\n",
      "Epoch 138/500 | Train Loss: 0.3713 | Train Acc: 0.8370 | Val Loss: 0.4355 | Val Acc: 0.8000\n",
      "Epoch 139/500 | Train Loss: 0.3402 | Train Acc: 0.8519 | Val Loss: 0.4666 | Val Acc: 0.8370\n",
      "Epoch 140/500 | Train Loss: 0.3329 | Train Acc: 0.8648 | Val Loss: 0.4790 | Val Acc: 0.8222\n",
      "Epoch 141/500 | Train Loss: 0.3221 | Train Acc: 0.8648 | Val Loss: 0.4908 | Val Acc: 0.8444\n",
      "Epoch 142/500 | Train Loss: 0.3217 | Train Acc: 0.8593 | Val Loss: 0.4730 | Val Acc: 0.8000\n",
      "Epoch 143/500 | Train Loss: 0.3114 | Train Acc: 0.8778 | Val Loss: 0.4981 | Val Acc: 0.7704\n",
      "Epoch 144/500 | Train Loss: 0.3498 | Train Acc: 0.8500 | Val Loss: 0.4529 | Val Acc: 0.7926\n",
      "Epoch 145/500 | Train Loss: 0.3133 | Train Acc: 0.8796 | Val Loss: 0.4822 | Val Acc: 0.7926\n",
      "Epoch 146/500 | Train Loss: 0.3138 | Train Acc: 0.8519 | Val Loss: 0.4322 | Val Acc: 0.7926\n",
      "Epoch 147/500 | Train Loss: 0.3419 | Train Acc: 0.8352 | Val Loss: 0.4516 | Val Acc: 0.8667\n",
      "Epoch 148/500 | Train Loss: 0.3270 | Train Acc: 0.8519 | Val Loss: 0.5478 | Val Acc: 0.8296\n",
      "Epoch 149/500 | Train Loss: 0.3486 | Train Acc: 0.8574 | Val Loss: 0.4444 | Val Acc: 0.8296\n",
      "Epoch 150/500 | Train Loss: 0.3176 | Train Acc: 0.8685 | Val Loss: 0.5325 | Val Acc: 0.8519\n",
      "Epoch 151/500 | Train Loss: 0.3035 | Train Acc: 0.8741 | Val Loss: 0.5103 | Val Acc: 0.8148\n",
      "Epoch 152/500 | Train Loss: 0.3265 | Train Acc: 0.8704 | Val Loss: 0.4654 | Val Acc: 0.7926\n",
      "Epoch 153/500 | Train Loss: 0.3255 | Train Acc: 0.8519 | Val Loss: 0.4684 | Val Acc: 0.7778\n",
      "Epoch 154/500 | Train Loss: 0.3206 | Train Acc: 0.8481 | Val Loss: 0.4781 | Val Acc: 0.7704\n",
      "Epoch 155/500 | Train Loss: 0.3631 | Train Acc: 0.8407 | Val Loss: 0.5020 | Val Acc: 0.8296\n",
      "Epoch 156/500 | Train Loss: 0.3241 | Train Acc: 0.8593 | Val Loss: 0.4918 | Val Acc: 0.7630\n",
      "Epoch 157/500 | Train Loss: 0.3150 | Train Acc: 0.8611 | Val Loss: 0.5469 | Val Acc: 0.8148\n",
      "Epoch 158/500 | Train Loss: 0.3220 | Train Acc: 0.8648 | Val Loss: 0.4634 | Val Acc: 0.8519\n",
      "Epoch 159/500 | Train Loss: 0.3267 | Train Acc: 0.8556 | Val Loss: 0.4718 | Val Acc: 0.7852\n",
      "Epoch 160/500 | Train Loss: 0.2916 | Train Acc: 0.8796 | Val Loss: 0.4826 | Val Acc: 0.7852\n",
      "Epoch 161/500 | Train Loss: 0.3116 | Train Acc: 0.8481 | Val Loss: 0.4588 | Val Acc: 0.8296\n",
      "Epoch 162/500 | Train Loss: 0.2925 | Train Acc: 0.8685 | Val Loss: 0.4965 | Val Acc: 0.8000\n",
      "Epoch 163/500 | Train Loss: 0.3018 | Train Acc: 0.8778 | Val Loss: 0.5247 | Val Acc: 0.8370\n",
      "Epoch 164/500 | Train Loss: 0.3072 | Train Acc: 0.8685 | Val Loss: 0.5272 | Val Acc: 0.8222\n",
      "Epoch 165/500 | Train Loss: 0.3296 | Train Acc: 0.8556 | Val Loss: 0.5751 | Val Acc: 0.8667\n",
      "Epoch 166/500 | Train Loss: 0.3388 | Train Acc: 0.8667 | Val Loss: 0.4707 | Val Acc: 0.8074\n",
      "Epoch 167/500 | Train Loss: 0.3306 | Train Acc: 0.8741 | Val Loss: 0.5067 | Val Acc: 0.8444\n",
      "Epoch 168/500 | Train Loss: 0.3017 | Train Acc: 0.8630 | Val Loss: 0.4876 | Val Acc: 0.8148\n",
      "Epoch 169/500 | Train Loss: 0.2980 | Train Acc: 0.8648 | Val Loss: 0.4870 | Val Acc: 0.8222\n",
      "Epoch 170/500 | Train Loss: 0.2851 | Train Acc: 0.8889 | Val Loss: 0.6364 | Val Acc: 0.8370\n",
      "Epoch 171/500 | Train Loss: 0.2633 | Train Acc: 0.9019 | Val Loss: 0.5701 | Val Acc: 0.8444\n",
      "Epoch 172/500 | Train Loss: 0.2968 | Train Acc: 0.8963 | Val Loss: 0.5404 | Val Acc: 0.8519\n",
      "Epoch 173/500 | Train Loss: 0.3301 | Train Acc: 0.8278 | Val Loss: 0.4649 | Val Acc: 0.7926\n",
      "Epoch 174/500 | Train Loss: 0.3017 | Train Acc: 0.8685 | Val Loss: 0.4655 | Val Acc: 0.8000\n",
      "Epoch 175/500 | Train Loss: 0.3021 | Train Acc: 0.8611 | Val Loss: 0.5889 | Val Acc: 0.8370\n",
      "Epoch 176/500 | Train Loss: 0.2761 | Train Acc: 0.8907 | Val Loss: 0.5408 | Val Acc: 0.8370\n",
      "Epoch 177/500 | Train Loss: 0.2894 | Train Acc: 0.8722 | Val Loss: 0.5101 | Val Acc: 0.7852\n",
      "Epoch 178/500 | Train Loss: 0.3153 | Train Acc: 0.8815 | Val Loss: 0.4602 | Val Acc: 0.8296\n",
      "Epoch 179/500 | Train Loss: 0.3216 | Train Acc: 0.8685 | Val Loss: 0.4231 | Val Acc: 0.7259\n",
      "Epoch 180/500 | Train Loss: 0.3360 | Train Acc: 0.8519 | Val Loss: 0.4252 | Val Acc: 0.8222\n",
      "Epoch 181/500 | Train Loss: 0.3287 | Train Acc: 0.8500 | Val Loss: 0.4846 | Val Acc: 0.8074\n",
      "Epoch 182/500 | Train Loss: 0.3151 | Train Acc: 0.8741 | Val Loss: 0.5220 | Val Acc: 0.8296\n",
      "Epoch 183/500 | Train Loss: 0.3205 | Train Acc: 0.8315 | Val Loss: 0.4680 | Val Acc: 0.7704\n",
      "Epoch 184/500 | Train Loss: 0.2721 | Train Acc: 0.8833 | Val Loss: 0.5410 | Val Acc: 0.8519\n",
      "Epoch 185/500 | Train Loss: 0.3139 | Train Acc: 0.8722 | Val Loss: 0.5161 | Val Acc: 0.8000\n",
      "Epoch 186/500 | Train Loss: 0.3172 | Train Acc: 0.8500 | Val Loss: 0.4438 | Val Acc: 0.8000\n",
      "Epoch 187/500 | Train Loss: 0.2980 | Train Acc: 0.8778 | Val Loss: 0.5420 | Val Acc: 0.8000\n",
      "Epoch 188/500 | Train Loss: 0.2887 | Train Acc: 0.8685 | Val Loss: 0.4865 | Val Acc: 0.8444\n",
      "Epoch 189/500 | Train Loss: 0.3071 | Train Acc: 0.8667 | Val Loss: 0.4893 | Val Acc: 0.8519\n",
      "Epoch 190/500 | Train Loss: 0.2799 | Train Acc: 0.8796 | Val Loss: 0.5045 | Val Acc: 0.8370\n",
      "Epoch 191/500 | Train Loss: 0.3108 | Train Acc: 0.8593 | Val Loss: 0.6221 | Val Acc: 0.8519\n",
      "Epoch 192/500 | Train Loss: 0.3043 | Train Acc: 0.8667 | Val Loss: 0.4677 | Val Acc: 0.7852\n",
      "Epoch 193/500 | Train Loss: 0.3152 | Train Acc: 0.8519 | Val Loss: 0.5096 | Val Acc: 0.8296\n",
      "Epoch 194/500 | Train Loss: 0.3080 | Train Acc: 0.8722 | Val Loss: 0.4964 | Val Acc: 0.8444\n",
      "Epoch 195/500 | Train Loss: 0.2930 | Train Acc: 0.8704 | Val Loss: 0.5163 | Val Acc: 0.8370\n",
      "Epoch 196/500 | Train Loss: 0.2991 | Train Acc: 0.8667 | Val Loss: 0.4571 | Val Acc: 0.8148\n",
      "Epoch 197/500 | Train Loss: 0.3040 | Train Acc: 0.8611 | Val Loss: 0.4483 | Val Acc: 0.7778\n",
      "Epoch 198/500 | Train Loss: 0.2935 | Train Acc: 0.8870 | Val Loss: 0.5173 | Val Acc: 0.8370\n",
      "Epoch 199/500 | Train Loss: 0.2888 | Train Acc: 0.8685 | Val Loss: 0.5563 | Val Acc: 0.8222\n",
      "Epoch 200/500 | Train Loss: 0.2931 | Train Acc: 0.8685 | Val Loss: 0.4885 | Val Acc: 0.8370\n",
      "Epoch 201/500 | Train Loss: 0.2668 | Train Acc: 0.8796 | Val Loss: 0.6336 | Val Acc: 0.8741\n",
      "Epoch 202/500 | Train Loss: 0.2843 | Train Acc: 0.8704 | Val Loss: 0.5882 | Val Acc: 0.8593\n",
      "Epoch 203/500 | Train Loss: 0.3294 | Train Acc: 0.8519 | Val Loss: 0.4765 | Val Acc: 0.8593\n",
      "Epoch 204/500 | Train Loss: 0.2886 | Train Acc: 0.8556 | Val Loss: 0.5275 | Val Acc: 0.8444\n",
      "Epoch 205/500 | Train Loss: 0.2865 | Train Acc: 0.8611 | Val Loss: 0.5435 | Val Acc: 0.8519\n",
      "Epoch 206/500 | Train Loss: 0.2900 | Train Acc: 0.8759 | Val Loss: 0.5494 | Val Acc: 0.8222\n",
      "Epoch 207/500 | Train Loss: 0.3015 | Train Acc: 0.8611 | Val Loss: 0.4866 | Val Acc: 0.8074\n",
      "Epoch 208/500 | Train Loss: 0.2691 | Train Acc: 0.8852 | Val Loss: 0.5359 | Val Acc: 0.8074\n",
      "Epoch 209/500 | Train Loss: 0.2770 | Train Acc: 0.8870 | Val Loss: 0.5852 | Val Acc: 0.8519\n",
      "Epoch 210/500 | Train Loss: 0.3000 | Train Acc: 0.8556 | Val Loss: 0.6183 | Val Acc: 0.8519\n",
      "Epoch 211/500 | Train Loss: 0.2788 | Train Acc: 0.8889 | Val Loss: 0.5350 | Val Acc: 0.8444\n",
      "Epoch 212/500 | Train Loss: 0.3041 | Train Acc: 0.8722 | Val Loss: 0.5385 | Val Acc: 0.8148\n",
      "Epoch 213/500 | Train Loss: 0.2726 | Train Acc: 0.8722 | Val Loss: 0.6575 | Val Acc: 0.8519\n",
      "Epoch 214/500 | Train Loss: 0.3025 | Train Acc: 0.8759 | Val Loss: 0.4790 | Val Acc: 0.7852\n",
      "Epoch 215/500 | Train Loss: 0.2837 | Train Acc: 0.8667 | Val Loss: 0.4856 | Val Acc: 0.8000\n",
      "Epoch 216/500 | Train Loss: 0.2652 | Train Acc: 0.8778 | Val Loss: 0.5938 | Val Acc: 0.8444\n",
      "Epoch 217/500 | Train Loss: 0.2772 | Train Acc: 0.8870 | Val Loss: 0.5834 | Val Acc: 0.8370\n",
      "Epoch 218/500 | Train Loss: 0.2591 | Train Acc: 0.8796 | Val Loss: 0.6227 | Val Acc: 0.8519\n",
      "Epoch 219/500 | Train Loss: 0.2634 | Train Acc: 0.8870 | Val Loss: 0.5774 | Val Acc: 0.8370\n",
      "Epoch 220/500 | Train Loss: 0.2830 | Train Acc: 0.8481 | Val Loss: 0.5522 | Val Acc: 0.8741\n",
      "Epoch 221/500 | Train Loss: 0.2924 | Train Acc: 0.8593 | Val Loss: 0.4816 | Val Acc: 0.8222\n",
      "Epoch 222/500 | Train Loss: 0.2701 | Train Acc: 0.8963 | Val Loss: 0.5537 | Val Acc: 0.8519\n",
      "Epoch 223/500 | Train Loss: 0.2788 | Train Acc: 0.8704 | Val Loss: 0.5287 | Val Acc: 0.8000\n",
      "Epoch 224/500 | Train Loss: 0.2821 | Train Acc: 0.8907 | Val Loss: 0.5450 | Val Acc: 0.8593\n",
      "Epoch 225/500 | Train Loss: 0.2836 | Train Acc: 0.8778 | Val Loss: 0.5792 | Val Acc: 0.8519\n",
      "Epoch 226/500 | Train Loss: 0.2913 | Train Acc: 0.8778 | Val Loss: 0.5046 | Val Acc: 0.8370\n",
      "Epoch 227/500 | Train Loss: 0.2545 | Train Acc: 0.8870 | Val Loss: 0.5942 | Val Acc: 0.8519\n",
      "Epoch 228/500 | Train Loss: 0.2893 | Train Acc: 0.8648 | Val Loss: 0.5246 | Val Acc: 0.8593\n",
      "Epoch 229/500 | Train Loss: 0.2844 | Train Acc: 0.8500 | Val Loss: 0.5276 | Val Acc: 0.8222\n",
      "Epoch 230/500 | Train Loss: 0.2893 | Train Acc: 0.8648 | Val Loss: 0.4815 | Val Acc: 0.7778\n",
      "Epoch 231/500 | Train Loss: 0.2771 | Train Acc: 0.8759 | Val Loss: 0.5062 | Val Acc: 0.8593\n",
      "Epoch 232/500 | Train Loss: 0.2964 | Train Acc: 0.8852 | Val Loss: 0.4828 | Val Acc: 0.8222\n",
      "Epoch 233/500 | Train Loss: 0.2941 | Train Acc: 0.8407 | Val Loss: 0.6212 | Val Acc: 0.8519\n",
      "Epoch 234/500 | Train Loss: 0.2787 | Train Acc: 0.8611 | Val Loss: 0.4940 | Val Acc: 0.8000\n",
      "Epoch 235/500 | Train Loss: 0.2600 | Train Acc: 0.8981 | Val Loss: 0.5569 | Val Acc: 0.8370\n",
      "Epoch 236/500 | Train Loss: 0.2704 | Train Acc: 0.8685 | Val Loss: 0.5117 | Val Acc: 0.8519\n",
      "Epoch 237/500 | Train Loss: 0.2725 | Train Acc: 0.8926 | Val Loss: 0.5664 | Val Acc: 0.8000\n",
      "Epoch 238/500 | Train Loss: 0.2933 | Train Acc: 0.8741 | Val Loss: 0.5106 | Val Acc: 0.8222\n",
      "Epoch 239/500 | Train Loss: 0.2848 | Train Acc: 0.8667 | Val Loss: 0.5758 | Val Acc: 0.8370\n",
      "Epoch 240/500 | Train Loss: 0.2692 | Train Acc: 0.8907 | Val Loss: 0.6088 | Val Acc: 0.8593\n",
      "Epoch 241/500 | Train Loss: 0.2572 | Train Acc: 0.8852 | Val Loss: 0.5527 | Val Acc: 0.8444\n",
      "Epoch 242/500 | Train Loss: 0.2707 | Train Acc: 0.8648 | Val Loss: 0.6013 | Val Acc: 0.8593\n",
      "Epoch 243/500 | Train Loss: 0.2999 | Train Acc: 0.8556 | Val Loss: 0.4961 | Val Acc: 0.8370\n",
      "Epoch 244/500 | Train Loss: 0.2691 | Train Acc: 0.8630 | Val Loss: 0.5235 | Val Acc: 0.8444\n",
      "Epoch 245/500 | Train Loss: 0.2640 | Train Acc: 0.8759 | Val Loss: 0.5345 | Val Acc: 0.8222\n",
      "Epoch 246/500 | Train Loss: 0.2776 | Train Acc: 0.8981 | Val Loss: 0.5575 | Val Acc: 0.8593\n",
      "Epoch 247/500 | Train Loss: 0.2558 | Train Acc: 0.8870 | Val Loss: 0.6506 | Val Acc: 0.8519\n",
      "Epoch 248/500 | Train Loss: 0.2853 | Train Acc: 0.8704 | Val Loss: 0.6095 | Val Acc: 0.8222\n",
      "Epoch 249/500 | Train Loss: 0.2670 | Train Acc: 0.8852 | Val Loss: 0.5842 | Val Acc: 0.8593\n",
      "Epoch 250/500 | Train Loss: 0.2621 | Train Acc: 0.8944 | Val Loss: 0.6253 | Val Acc: 0.8370\n",
      "Epoch 251/500 | Train Loss: 0.2383 | Train Acc: 0.8759 | Val Loss: 0.5745 | Val Acc: 0.8000\n",
      "Epoch 252/500 | Train Loss: 0.2813 | Train Acc: 0.8722 | Val Loss: 0.5034 | Val Acc: 0.7926\n",
      "Epoch 253/500 | Train Loss: 0.2866 | Train Acc: 0.8574 | Val Loss: 0.4869 | Val Acc: 0.8000\n",
      "Epoch 254/500 | Train Loss: 0.2861 | Train Acc: 0.8537 | Val Loss: 0.5979 | Val Acc: 0.8593\n",
      "Epoch 255/500 | Train Loss: 0.2751 | Train Acc: 0.8722 | Val Loss: 0.5577 | Val Acc: 0.8593\n",
      "Epoch 256/500 | Train Loss: 0.2798 | Train Acc: 0.8556 | Val Loss: 0.6790 | Val Acc: 0.8593\n",
      "Epoch 257/500 | Train Loss: 0.2641 | Train Acc: 0.8870 | Val Loss: 0.5304 | Val Acc: 0.8074\n",
      "Epoch 258/500 | Train Loss: 0.2765 | Train Acc: 0.8852 | Val Loss: 0.5053 | Val Acc: 0.7926\n",
      "Epoch 259/500 | Train Loss: 0.2601 | Train Acc: 0.8889 | Val Loss: 0.5605 | Val Acc: 0.8000\n",
      "Epoch 260/500 | Train Loss: 0.2610 | Train Acc: 0.8833 | Val Loss: 0.5588 | Val Acc: 0.8148\n",
      "Epoch 261/500 | Train Loss: 0.2763 | Train Acc: 0.8759 | Val Loss: 0.5670 | Val Acc: 0.8741\n",
      "Epoch 262/500 | Train Loss: 0.2673 | Train Acc: 0.8444 | Val Loss: 0.5504 | Val Acc: 0.8074\n",
      "Epoch 263/500 | Train Loss: 0.2755 | Train Acc: 0.8519 | Val Loss: 0.4757 | Val Acc: 0.7704\n",
      "Epoch 264/500 | Train Loss: 0.2846 | Train Acc: 0.8389 | Val Loss: 0.5420 | Val Acc: 0.8148\n",
      "Epoch 265/500 | Train Loss: 0.2511 | Train Acc: 0.8722 | Val Loss: 0.7568 | Val Acc: 0.8667\n",
      "Epoch 266/500 | Train Loss: 0.2792 | Train Acc: 0.8741 | Val Loss: 0.4611 | Val Acc: 0.8000\n",
      "Epoch 267/500 | Train Loss: 0.2797 | Train Acc: 0.8556 | Val Loss: 0.5490 | Val Acc: 0.8370\n",
      "Epoch 268/500 | Train Loss: 0.2827 | Train Acc: 0.8889 | Val Loss: 0.6158 | Val Acc: 0.7926\n",
      "Epoch 269/500 | Train Loss: 0.2753 | Train Acc: 0.8667 | Val Loss: 0.4718 | Val Acc: 0.7852\n",
      "Epoch 270/500 | Train Loss: 0.2602 | Train Acc: 0.8815 | Val Loss: 0.5407 | Val Acc: 0.8074\n",
      "Epoch 271/500 | Train Loss: 0.2778 | Train Acc: 0.8685 | Val Loss: 0.5430 | Val Acc: 0.8370\n",
      "Epoch 272/500 | Train Loss: 0.2528 | Train Acc: 0.8833 | Val Loss: 0.5496 | Val Acc: 0.8370\n",
      "Epoch 273/500 | Train Loss: 0.2754 | Train Acc: 0.8815 | Val Loss: 0.5996 | Val Acc: 0.8444\n",
      "Epoch 274/500 | Train Loss: 0.2675 | Train Acc: 0.8593 | Val Loss: 0.6036 | Val Acc: 0.8593\n",
      "Epoch 275/500 | Train Loss: 0.2723 | Train Acc: 0.8611 | Val Loss: 0.5403 | Val Acc: 0.8222\n",
      "Epoch 276/500 | Train Loss: 0.2593 | Train Acc: 0.8852 | Val Loss: 0.5210 | Val Acc: 0.8444\n",
      "Epoch 277/500 | Train Loss: 0.2702 | Train Acc: 0.8648 | Val Loss: 0.6112 | Val Acc: 0.8815\n",
      "Epoch 278/500 | Train Loss: 0.3204 | Train Acc: 0.8574 | Val Loss: 0.4932 | Val Acc: 0.8074\n",
      "Epoch 279/500 | Train Loss: 0.2685 | Train Acc: 0.8778 | Val Loss: 0.5400 | Val Acc: 0.8000\n",
      "Epoch 280/500 | Train Loss: 0.2806 | Train Acc: 0.8667 | Val Loss: 0.5204 | Val Acc: 0.8370\n",
      "Epoch 281/500 | Train Loss: 0.2780 | Train Acc: 0.8593 | Val Loss: 0.5182 | Val Acc: 0.8370\n",
      "Epoch 282/500 | Train Loss: 0.2535 | Train Acc: 0.8833 | Val Loss: 0.6761 | Val Acc: 0.8593\n",
      "Epoch 283/500 | Train Loss: 0.2899 | Train Acc: 0.8741 | Val Loss: 0.5830 | Val Acc: 0.8148\n",
      "Epoch 284/500 | Train Loss: 0.2856 | Train Acc: 0.8167 | Val Loss: 0.4935 | Val Acc: 0.8667\n",
      "Epoch 285/500 | Train Loss: 0.2660 | Train Acc: 0.8722 | Val Loss: 0.5508 | Val Acc: 0.8519\n",
      "Epoch 286/500 | Train Loss: 0.2512 | Train Acc: 0.8778 | Val Loss: 0.6918 | Val Acc: 0.8519\n",
      "Epoch 287/500 | Train Loss: 0.2874 | Train Acc: 0.8574 | Val Loss: 0.5248 | Val Acc: 0.7852\n",
      "Epoch 288/500 | Train Loss: 0.2547 | Train Acc: 0.8833 | Val Loss: 0.6383 | Val Acc: 0.8593\n",
      "Epoch 289/500 | Train Loss: 0.2736 | Train Acc: 0.9000 | Val Loss: 0.5267 | Val Acc: 0.8000\n",
      "Epoch 290/500 | Train Loss: 0.2736 | Train Acc: 0.8611 | Val Loss: 0.7037 | Val Acc: 0.8593\n",
      "Epoch 291/500 | Train Loss: 0.2710 | Train Acc: 0.8704 | Val Loss: 0.6624 | Val Acc: 0.8370\n",
      "Epoch 292/500 | Train Loss: 0.2355 | Train Acc: 0.8889 | Val Loss: 0.6156 | Val Acc: 0.8593\n",
      "Epoch 293/500 | Train Loss: 0.2607 | Train Acc: 0.8796 | Val Loss: 0.5244 | Val Acc: 0.8444\n",
      "Epoch 294/500 | Train Loss: 0.2522 | Train Acc: 0.8815 | Val Loss: 0.7181 | Val Acc: 0.8370\n",
      "Epoch 295/500 | Train Loss: 0.2645 | Train Acc: 0.8704 | Val Loss: 0.5042 | Val Acc: 0.8000\n",
      "Epoch 296/500 | Train Loss: 0.2812 | Train Acc: 0.8537 | Val Loss: 0.5832 | Val Acc: 0.8741\n",
      "Epoch 297/500 | Train Loss: 0.2646 | Train Acc: 0.8648 | Val Loss: 0.5613 | Val Acc: 0.8444\n",
      "Epoch 298/500 | Train Loss: 0.2667 | Train Acc: 0.8426 | Val Loss: 0.6401 | Val Acc: 0.8222\n",
      "Epoch 299/500 | Train Loss: 0.2621 | Train Acc: 0.8648 | Val Loss: 0.5330 | Val Acc: 0.8444\n",
      "Epoch 300/500 | Train Loss: 0.2589 | Train Acc: 0.8778 | Val Loss: 0.5888 | Val Acc: 0.8519\n",
      "Epoch 301/500 | Train Loss: 0.2391 | Train Acc: 0.8889 | Val Loss: 0.6028 | Val Acc: 0.8148\n",
      "Epoch 302/500 | Train Loss: 0.2732 | Train Acc: 0.8519 | Val Loss: 0.4986 | Val Acc: 0.8222\n",
      "Epoch 303/500 | Train Loss: 0.2875 | Train Acc: 0.8685 | Val Loss: 0.5141 | Val Acc: 0.7926\n",
      "Epoch 304/500 | Train Loss: 0.2818 | Train Acc: 0.8611 | Val Loss: 0.4903 | Val Acc: 0.8370\n",
      "Epoch 305/500 | Train Loss: 0.2594 | Train Acc: 0.8667 | Val Loss: 0.5410 | Val Acc: 0.7926\n",
      "Epoch 306/500 | Train Loss: 0.2684 | Train Acc: 0.8593 | Val Loss: 0.4571 | Val Acc: 0.8148\n",
      "Epoch 307/500 | Train Loss: 0.2448 | Train Acc: 0.8926 | Val Loss: 0.6010 | Val Acc: 0.8222\n",
      "Epoch 308/500 | Train Loss: 0.2939 | Train Acc: 0.8648 | Val Loss: 0.4877 | Val Acc: 0.8593\n",
      "Epoch 309/500 | Train Loss: 0.2825 | Train Acc: 0.8500 | Val Loss: 0.5265 | Val Acc: 0.8296\n",
      "Epoch 310/500 | Train Loss: 0.2612 | Train Acc: 0.8593 | Val Loss: 0.6132 | Val Acc: 0.8444\n",
      "Epoch 311/500 | Train Loss: 0.2336 | Train Acc: 0.8889 | Val Loss: 0.6844 | Val Acc: 0.8741\n",
      "Epoch 312/500 | Train Loss: 0.2381 | Train Acc: 0.8815 | Val Loss: 0.6895 | Val Acc: 0.8667\n",
      "Epoch 313/500 | Train Loss: 0.2598 | Train Acc: 0.8796 | Val Loss: 0.6127 | Val Acc: 0.8519\n",
      "Epoch 314/500 | Train Loss: 0.2357 | Train Acc: 0.9037 | Val Loss: 0.6343 | Val Acc: 0.8667\n",
      "Epoch 315/500 | Train Loss: 0.2523 | Train Acc: 0.8667 | Val Loss: 0.5928 | Val Acc: 0.8444\n",
      "Epoch 316/500 | Train Loss: 0.2402 | Train Acc: 0.8981 | Val Loss: 0.6173 | Val Acc: 0.8074\n",
      "Epoch 317/500 | Train Loss: 0.2327 | Train Acc: 0.8870 | Val Loss: 0.6940 | Val Acc: 0.8074\n",
      "Epoch 318/500 | Train Loss: 0.2429 | Train Acc: 0.8944 | Val Loss: 0.6080 | Val Acc: 0.8370\n",
      "Epoch 319/500 | Train Loss: 0.2542 | Train Acc: 0.8630 | Val Loss: 0.6677 | Val Acc: 0.8667\n",
      "Epoch 320/500 | Train Loss: 0.2567 | Train Acc: 0.8815 | Val Loss: 0.6643 | Val Acc: 0.8000\n",
      "Epoch 321/500 | Train Loss: 0.2637 | Train Acc: 0.8907 | Val Loss: 0.6777 | Val Acc: 0.7852\n",
      "Epoch 322/500 | Train Loss: 0.2710 | Train Acc: 0.8796 | Val Loss: 0.5114 | Val Acc: 0.8000\n",
      "Epoch 323/500 | Train Loss: 0.2404 | Train Acc: 0.8833 | Val Loss: 0.8057 | Val Acc: 0.8519\n",
      "Epoch 324/500 | Train Loss: 0.2798 | Train Acc: 0.8963 | Val Loss: 0.5736 | Val Acc: 0.8519\n",
      "Epoch 325/500 | Train Loss: 0.2697 | Train Acc: 0.8704 | Val Loss: 0.5510 | Val Acc: 0.8148\n",
      "Epoch 326/500 | Train Loss: 0.2588 | Train Acc: 0.9037 | Val Loss: 0.5607 | Val Acc: 0.8074\n",
      "Epoch 327/500 | Train Loss: 0.2566 | Train Acc: 0.8611 | Val Loss: 0.5521 | Val Acc: 0.8667\n",
      "Epoch 328/500 | Train Loss: 0.2569 | Train Acc: 0.8796 | Val Loss: 0.6528 | Val Acc: 0.8000\n",
      "Epoch 329/500 | Train Loss: 0.2444 | Train Acc: 0.8759 | Val Loss: 0.6470 | Val Acc: 0.8519\n",
      "Epoch 330/500 | Train Loss: 0.2230 | Train Acc: 0.8870 | Val Loss: 0.7238 | Val Acc: 0.8222\n",
      "Epoch 331/500 | Train Loss: 0.2627 | Train Acc: 0.8852 | Val Loss: 0.5068 | Val Acc: 0.8000\n",
      "Epoch 332/500 | Train Loss: 0.2527 | Train Acc: 0.8556 | Val Loss: 0.5836 | Val Acc: 0.8296\n",
      "Epoch 333/500 | Train Loss: 0.2522 | Train Acc: 0.9074 | Val Loss: 0.5594 | Val Acc: 0.8000\n",
      "Epoch 334/500 | Train Loss: 0.2523 | Train Acc: 0.8481 | Val Loss: 0.6183 | Val Acc: 0.8593\n",
      "Epoch 335/500 | Train Loss: 0.2649 | Train Acc: 0.8537 | Val Loss: 0.5571 | Val Acc: 0.8519\n",
      "Epoch 336/500 | Train Loss: 0.2494 | Train Acc: 0.8870 | Val Loss: 0.7456 | Val Acc: 0.8000\n",
      "Epoch 337/500 | Train Loss: 0.2393 | Train Acc: 0.8907 | Val Loss: 0.7535 | Val Acc: 0.8444\n",
      "Epoch 338/500 | Train Loss: 0.2507 | Train Acc: 0.8981 | Val Loss: 0.5714 | Val Acc: 0.8000\n",
      "Epoch 339/500 | Train Loss: 0.2364 | Train Acc: 0.8704 | Val Loss: 0.6926 | Val Acc: 0.8148\n",
      "Epoch 340/500 | Train Loss: 0.2479 | Train Acc: 0.8870 | Val Loss: 0.6628 | Val Acc: 0.8148\n",
      "Epoch 341/500 | Train Loss: 0.2384 | Train Acc: 0.8852 | Val Loss: 0.7629 | Val Acc: 0.8593\n",
      "Epoch 342/500 | Train Loss: 0.2459 | Train Acc: 0.8796 | Val Loss: 0.6033 | Val Acc: 0.7852\n",
      "Epoch 343/500 | Train Loss: 0.2343 | Train Acc: 0.8889 | Val Loss: 0.6925 | Val Acc: 0.8074\n",
      "Epoch 344/500 | Train Loss: 0.2603 | Train Acc: 0.8815 | Val Loss: 0.7204 | Val Acc: 0.8148\n",
      "Epoch 345/500 | Train Loss: 0.2353 | Train Acc: 0.8667 | Val Loss: 0.7441 | Val Acc: 0.8593\n",
      "Epoch 346/500 | Train Loss: 0.2595 | Train Acc: 0.8741 | Val Loss: 0.5854 | Val Acc: 0.7778\n",
      "Epoch 347/500 | Train Loss: 0.2506 | Train Acc: 0.8611 | Val Loss: 0.6294 | Val Acc: 0.8593\n",
      "Epoch 348/500 | Train Loss: 0.2420 | Train Acc: 0.8852 | Val Loss: 0.7929 | Val Acc: 0.8370\n",
      "Epoch 349/500 | Train Loss: 0.2612 | Train Acc: 0.8870 | Val Loss: 0.5874 | Val Acc: 0.8667\n",
      "Epoch 350/500 | Train Loss: 0.2442 | Train Acc: 0.8722 | Val Loss: 0.6413 | Val Acc: 0.8667\n",
      "Epoch 351/500 | Train Loss: 0.2291 | Train Acc: 0.8870 | Val Loss: 0.7754 | Val Acc: 0.8593\n",
      "Epoch 352/500 | Train Loss: 0.2807 | Train Acc: 0.8537 | Val Loss: 0.7537 | Val Acc: 0.8370\n",
      "Epoch 353/500 | Train Loss: 0.2570 | Train Acc: 0.8926 | Val Loss: 0.8087 | Val Acc: 0.8444\n",
      "Epoch 354/500 | Train Loss: 0.2479 | Train Acc: 0.9000 | Val Loss: 0.6167 | Val Acc: 0.8222\n",
      "Epoch 355/500 | Train Loss: 0.2428 | Train Acc: 0.8778 | Val Loss: 0.7486 | Val Acc: 0.8000\n",
      "Epoch 356/500 | Train Loss: 0.2293 | Train Acc: 0.8722 | Val Loss: 0.6552 | Val Acc: 0.8370\n",
      "Epoch 357/500 | Train Loss: 0.2514 | Train Acc: 0.8852 | Val Loss: 0.5755 | Val Acc: 0.7630\n",
      "Epoch 358/500 | Train Loss: 0.2803 | Train Acc: 0.8463 | Val Loss: 0.5680 | Val Acc: 0.8296\n",
      "Epoch 359/500 | Train Loss: 0.2494 | Train Acc: 0.8537 | Val Loss: 0.5725 | Val Acc: 0.7778\n",
      "Epoch 360/500 | Train Loss: 0.2476 | Train Acc: 0.8648 | Val Loss: 0.6289 | Val Acc: 0.8370\n",
      "Epoch 361/500 | Train Loss: 0.2465 | Train Acc: 0.8741 | Val Loss: 0.6480 | Val Acc: 0.8444\n",
      "Epoch 362/500 | Train Loss: 0.2666 | Train Acc: 0.8537 | Val Loss: 0.6449 | Val Acc: 0.8222\n",
      "Epoch 363/500 | Train Loss: 0.2708 | Train Acc: 0.8463 | Val Loss: 0.7232 | Val Acc: 0.8000\n",
      "Epoch 364/500 | Train Loss: 0.2633 | Train Acc: 0.8741 | Val Loss: 0.5700 | Val Acc: 0.8000\n",
      "Epoch 365/500 | Train Loss: 0.2545 | Train Acc: 0.8870 | Val Loss: 0.7396 | Val Acc: 0.8444\n",
      "Epoch 366/500 | Train Loss: 0.2529 | Train Acc: 0.8963 | Val Loss: 0.6975 | Val Acc: 0.8444\n",
      "Epoch 367/500 | Train Loss: 0.2539 | Train Acc: 0.8944 | Val Loss: 0.7064 | Val Acc: 0.8593\n",
      "Epoch 368/500 | Train Loss: 0.2365 | Train Acc: 0.8963 | Val Loss: 0.7461 | Val Acc: 0.8519\n",
      "Epoch 369/500 | Train Loss: 0.2295 | Train Acc: 0.8926 | Val Loss: 0.6625 | Val Acc: 0.8222\n",
      "Epoch 370/500 | Train Loss: 0.2321 | Train Acc: 0.8889 | Val Loss: 0.7598 | Val Acc: 0.8519\n",
      "Epoch 371/500 | Train Loss: 0.2432 | Train Acc: 0.8907 | Val Loss: 0.5867 | Val Acc: 0.8296\n",
      "Epoch 372/500 | Train Loss: 0.2988 | Train Acc: 0.8463 | Val Loss: 0.4734 | Val Acc: 0.7852\n",
      "Epoch 373/500 | Train Loss: 0.2468 | Train Acc: 0.8796 | Val Loss: 0.6252 | Val Acc: 0.8444\n",
      "Epoch 374/500 | Train Loss: 0.2630 | Train Acc: 0.8704 | Val Loss: 0.5269 | Val Acc: 0.8296\n",
      "Epoch 375/500 | Train Loss: 0.2545 | Train Acc: 0.8741 | Val Loss: 0.6184 | Val Acc: 0.8148\n",
      "Epoch 376/500 | Train Loss: 0.2397 | Train Acc: 0.8481 | Val Loss: 0.6468 | Val Acc: 0.8444\n",
      "Epoch 377/500 | Train Loss: 0.2232 | Train Acc: 0.8593 | Val Loss: 0.6859 | Val Acc: 0.8296\n",
      "Epoch 378/500 | Train Loss: 0.2499 | Train Acc: 0.8611 | Val Loss: 0.7653 | Val Acc: 0.8296\n",
      "Epoch 379/500 | Train Loss: 0.2344 | Train Acc: 0.8593 | Val Loss: 0.7152 | Val Acc: 0.8444\n",
      "Epoch 380/500 | Train Loss: 0.2409 | Train Acc: 0.8926 | Val Loss: 0.7305 | Val Acc: 0.8519\n",
      "Epoch 381/500 | Train Loss: 0.2262 | Train Acc: 0.8852 | Val Loss: 0.6984 | Val Acc: 0.8148\n",
      "Epoch 382/500 | Train Loss: 0.2408 | Train Acc: 0.8556 | Val Loss: 0.5833 | Val Acc: 0.8370\n",
      "Epoch 383/500 | Train Loss: 0.2355 | Train Acc: 0.8611 | Val Loss: 0.6753 | Val Acc: 0.8296\n",
      "Epoch 384/500 | Train Loss: 0.2547 | Train Acc: 0.8741 | Val Loss: 0.8776 | Val Acc: 0.8370\n",
      "Epoch 385/500 | Train Loss: 0.2565 | Train Acc: 0.8704 | Val Loss: 0.5285 | Val Acc: 0.7778\n",
      "Epoch 386/500 | Train Loss: 0.2408 | Train Acc: 0.8685 | Val Loss: 0.6460 | Val Acc: 0.8815\n",
      "Epoch 387/500 | Train Loss: 0.2484 | Train Acc: 0.8556 | Val Loss: 0.6232 | Val Acc: 0.8815\n",
      "Epoch 388/500 | Train Loss: 0.2373 | Train Acc: 0.8741 | Val Loss: 0.6489 | Val Acc: 0.8667\n",
      "Epoch 389/500 | Train Loss: 0.2292 | Train Acc: 0.8889 | Val Loss: 0.6955 | Val Acc: 0.8519\n",
      "Epoch 390/500 | Train Loss: 0.2220 | Train Acc: 0.9000 | Val Loss: 0.7023 | Val Acc: 0.8519\n",
      "Epoch 391/500 | Train Loss: 0.2268 | Train Acc: 0.8889 | Val Loss: 0.6148 | Val Acc: 0.8074\n",
      "Epoch 392/500 | Train Loss: 0.2420 | Train Acc: 0.8593 | Val Loss: 0.6250 | Val Acc: 0.8370\n",
      "Epoch 393/500 | Train Loss: 0.2307 | Train Acc: 0.8815 | Val Loss: 0.6100 | Val Acc: 0.7852\n",
      "Epoch 394/500 | Train Loss: 0.2540 | Train Acc: 0.8574 | Val Loss: 0.5722 | Val Acc: 0.8148\n",
      "Epoch 395/500 | Train Loss: 0.2550 | Train Acc: 0.8463 | Val Loss: 0.5648 | Val Acc: 0.7926\n",
      "Epoch 396/500 | Train Loss: 0.2423 | Train Acc: 0.8704 | Val Loss: 0.6259 | Val Acc: 0.8148\n",
      "Epoch 397/500 | Train Loss: 0.2209 | Train Acc: 0.8852 | Val Loss: 0.7589 | Val Acc: 0.8741\n",
      "Epoch 398/500 | Train Loss: 0.2450 | Train Acc: 0.8630 | Val Loss: 0.6417 | Val Acc: 0.8074\n",
      "Epoch 399/500 | Train Loss: 0.2386 | Train Acc: 0.8852 | Val Loss: 0.6800 | Val Acc: 0.8370\n",
      "Epoch 400/500 | Train Loss: 0.2212 | Train Acc: 0.9037 | Val Loss: 0.6991 | Val Acc: 0.8519\n",
      "Epoch 401/500 | Train Loss: 0.2208 | Train Acc: 0.9037 | Val Loss: 0.6860 | Val Acc: 0.8593\n",
      "Epoch 402/500 | Train Loss: 0.2071 | Train Acc: 0.9130 | Val Loss: 0.6830 | Val Acc: 0.8000\n",
      "Epoch 403/500 | Train Loss: 0.2532 | Train Acc: 0.8815 | Val Loss: 0.6393 | Val Acc: 0.8000\n",
      "Epoch 404/500 | Train Loss: 0.2420 | Train Acc: 0.8907 | Val Loss: 0.6684 | Val Acc: 0.8074\n",
      "Epoch 405/500 | Train Loss: 0.2371 | Train Acc: 0.8926 | Val Loss: 0.6505 | Val Acc: 0.8519\n",
      "Epoch 406/500 | Train Loss: 0.2541 | Train Acc: 0.8519 | Val Loss: 0.6501 | Val Acc: 0.8148\n",
      "Epoch 407/500 | Train Loss: 0.2409 | Train Acc: 0.8648 | Val Loss: 0.6577 | Val Acc: 0.8370\n",
      "Epoch 408/500 | Train Loss: 0.2195 | Train Acc: 0.8796 | Val Loss: 0.7689 | Val Acc: 0.8444\n",
      "Epoch 409/500 | Train Loss: 0.2446 | Train Acc: 0.8741 | Val Loss: 0.6620 | Val Acc: 0.8370\n",
      "Epoch 410/500 | Train Loss: 0.2310 | Train Acc: 0.8796 | Val Loss: 0.7176 | Val Acc: 0.7926\n",
      "Epoch 411/500 | Train Loss: 0.2221 | Train Acc: 0.8907 | Val Loss: 0.6715 | Val Acc: 0.8074\n",
      "Epoch 412/500 | Train Loss: 0.2731 | Train Acc: 0.8815 | Val Loss: 0.6916 | Val Acc: 0.8000\n",
      "Epoch 413/500 | Train Loss: 0.2304 | Train Acc: 0.8907 | Val Loss: 0.6885 | Val Acc: 0.8000\n",
      "Epoch 414/500 | Train Loss: 0.2407 | Train Acc: 0.9093 | Val Loss: 0.6994 | Val Acc: 0.8444\n",
      "Epoch 415/500 | Train Loss: 0.2291 | Train Acc: 0.8981 | Val Loss: 0.6639 | Val Acc: 0.8593\n",
      "Epoch 416/500 | Train Loss: 0.2291 | Train Acc: 0.8852 | Val Loss: 0.6662 | Val Acc: 0.7926\n",
      "Epoch 417/500 | Train Loss: 0.2205 | Train Acc: 0.8944 | Val Loss: 0.7102 | Val Acc: 0.8000\n",
      "Epoch 418/500 | Train Loss: 0.2072 | Train Acc: 0.8759 | Val Loss: 0.7637 | Val Acc: 0.8444\n",
      "Epoch 419/500 | Train Loss: 0.2189 | Train Acc: 0.8778 | Val Loss: 0.6849 | Val Acc: 0.8000\n",
      "Epoch 420/500 | Train Loss: 0.2310 | Train Acc: 0.9056 | Val Loss: 0.7203 | Val Acc: 0.8296\n",
      "Epoch 421/500 | Train Loss: 0.2145 | Train Acc: 0.8981 | Val Loss: 0.7568 | Val Acc: 0.8222\n",
      "Epoch 422/500 | Train Loss: 0.2278 | Train Acc: 0.9056 | Val Loss: 0.8126 | Val Acc: 0.8370\n",
      "Epoch 423/500 | Train Loss: 0.2392 | Train Acc: 0.8796 | Val Loss: 0.6985 | Val Acc: 0.8370\n",
      "Epoch 424/500 | Train Loss: 0.2343 | Train Acc: 0.8944 | Val Loss: 0.8182 | Val Acc: 0.8593\n",
      "Epoch 425/500 | Train Loss: 0.2355 | Train Acc: 0.8667 | Val Loss: 0.7100 | Val Acc: 0.8519\n",
      "Epoch 426/500 | Train Loss: 0.2236 | Train Acc: 0.8963 | Val Loss: 0.7278 | Val Acc: 0.8296\n",
      "Epoch 427/500 | Train Loss: 0.2377 | Train Acc: 0.8759 | Val Loss: 0.6993 | Val Acc: 0.8074\n",
      "Epoch 428/500 | Train Loss: 0.2361 | Train Acc: 0.8907 | Val Loss: 0.6355 | Val Acc: 0.8370\n",
      "Epoch 429/500 | Train Loss: 0.2124 | Train Acc: 0.8815 | Val Loss: 0.6795 | Val Acc: 0.8593\n",
      "Epoch 430/500 | Train Loss: 0.2218 | Train Acc: 0.8722 | Val Loss: 0.7341 | Val Acc: 0.8148\n",
      "Epoch 431/500 | Train Loss: 0.2442 | Train Acc: 0.8704 | Val Loss: 0.5981 | Val Acc: 0.8000\n",
      "Epoch 432/500 | Train Loss: 0.2564 | Train Acc: 0.8593 | Val Loss: 0.6453 | Val Acc: 0.8074\n",
      "Epoch 433/500 | Train Loss: 0.2339 | Train Acc: 0.8870 | Val Loss: 0.8277 | Val Acc: 0.8519\n",
      "Epoch 434/500 | Train Loss: 0.2305 | Train Acc: 0.8907 | Val Loss: 0.6082 | Val Acc: 0.8148\n",
      "Epoch 435/500 | Train Loss: 0.2493 | Train Acc: 0.8685 | Val Loss: 0.5854 | Val Acc: 0.7556\n",
      "Epoch 436/500 | Train Loss: 0.2635 | Train Acc: 0.8648 | Val Loss: 0.6759 | Val Acc: 0.8148\n",
      "Epoch 437/500 | Train Loss: 0.2507 | Train Acc: 0.8574 | Val Loss: 0.6638 | Val Acc: 0.7852\n",
      "Epoch 438/500 | Train Loss: 0.2167 | Train Acc: 0.8870 | Val Loss: 0.7506 | Val Acc: 0.8519\n",
      "Epoch 439/500 | Train Loss: 0.2404 | Train Acc: 0.8833 | Val Loss: 0.6269 | Val Acc: 0.8148\n",
      "Epoch 440/500 | Train Loss: 0.2409 | Train Acc: 0.8333 | Val Loss: 0.7465 | Val Acc: 0.8296\n",
      "Epoch 441/500 | Train Loss: 0.2457 | Train Acc: 0.8667 | Val Loss: 0.6221 | Val Acc: 0.7926\n",
      "Epoch 442/500 | Train Loss: 0.2633 | Train Acc: 0.8593 | Val Loss: 0.6123 | Val Acc: 0.7926\n",
      "Epoch 443/500 | Train Loss: 0.2375 | Train Acc: 0.8667 | Val Loss: 0.8579 | Val Acc: 0.8519\n",
      "Epoch 444/500 | Train Loss: 0.2631 | Train Acc: 0.8796 | Val Loss: 0.6521 | Val Acc: 0.8222\n",
      "Epoch 445/500 | Train Loss: 0.2152 | Train Acc: 0.8722 | Val Loss: 0.7973 | Val Acc: 0.8667\n",
      "Epoch 446/500 | Train Loss: 0.2444 | Train Acc: 0.8722 | Val Loss: 0.7803 | Val Acc: 0.8667\n",
      "Epoch 447/500 | Train Loss: 0.2505 | Train Acc: 0.8889 | Val Loss: 0.6667 | Val Acc: 0.8370\n",
      "Epoch 448/500 | Train Loss: 0.2236 | Train Acc: 0.9000 | Val Loss: 0.7811 | Val Acc: 0.8444\n",
      "Epoch 449/500 | Train Loss: 0.2289 | Train Acc: 0.8704 | Val Loss: 0.7869 | Val Acc: 0.8370\n",
      "Epoch 450/500 | Train Loss: 0.2306 | Train Acc: 0.8870 | Val Loss: 0.5870 | Val Acc: 0.8000\n",
      "Epoch 451/500 | Train Loss: 0.2279 | Train Acc: 0.8778 | Val Loss: 0.6676 | Val Acc: 0.8222\n",
      "Epoch 452/500 | Train Loss: 0.2467 | Train Acc: 0.8722 | Val Loss: 0.6708 | Val Acc: 0.8519\n",
      "Epoch 453/500 | Train Loss: 0.2163 | Train Acc: 0.8907 | Val Loss: 0.7289 | Val Acc: 0.8000\n",
      "Epoch 454/500 | Train Loss: 0.2385 | Train Acc: 0.8870 | Val Loss: 0.6188 | Val Acc: 0.8074\n",
      "Epoch 455/500 | Train Loss: 0.2402 | Train Acc: 0.8704 | Val Loss: 0.6091 | Val Acc: 0.8000\n",
      "Epoch 456/500 | Train Loss: 0.2364 | Train Acc: 0.8741 | Val Loss: 0.6679 | Val Acc: 0.8000\n",
      "Epoch 457/500 | Train Loss: 0.2486 | Train Acc: 0.8611 | Val Loss: 0.7269 | Val Acc: 0.8296\n",
      "Epoch 458/500 | Train Loss: 0.2375 | Train Acc: 0.8611 | Val Loss: 0.6047 | Val Acc: 0.8074\n",
      "Epoch 459/500 | Train Loss: 0.2230 | Train Acc: 0.8704 | Val Loss: 0.7012 | Val Acc: 0.7852\n",
      "Epoch 460/500 | Train Loss: 0.2301 | Train Acc: 0.8537 | Val Loss: 0.7118 | Val Acc: 0.8222\n",
      "Epoch 461/500 | Train Loss: 0.2353 | Train Acc: 0.8648 | Val Loss: 0.7300 | Val Acc: 0.7778\n",
      "Epoch 462/500 | Train Loss: 0.2020 | Train Acc: 0.8889 | Val Loss: 0.8293 | Val Acc: 0.8519\n",
      "Epoch 463/500 | Train Loss: 0.2497 | Train Acc: 0.8444 | Val Loss: 0.6256 | Val Acc: 0.7778\n",
      "Epoch 464/500 | Train Loss: 0.2170 | Train Acc: 0.8704 | Val Loss: 0.7310 | Val Acc: 0.8000\n",
      "Epoch 465/500 | Train Loss: 0.2722 | Train Acc: 0.8389 | Val Loss: 0.7503 | Val Acc: 0.7852\n",
      "Epoch 466/500 | Train Loss: 0.2451 | Train Acc: 0.8444 | Val Loss: 0.7263 | Val Acc: 0.8296\n",
      "Epoch 467/500 | Train Loss: 0.2226 | Train Acc: 0.8611 | Val Loss: 0.6803 | Val Acc: 0.7926\n",
      "Epoch 468/500 | Train Loss: 0.2397 | Train Acc: 0.8648 | Val Loss: 0.6604 | Val Acc: 0.8000\n",
      "Epoch 469/500 | Train Loss: 0.2211 | Train Acc: 0.8759 | Val Loss: 0.7703 | Val Acc: 0.8222\n",
      "Epoch 470/500 | Train Loss: 0.2355 | Train Acc: 0.8667 | Val Loss: 0.5520 | Val Acc: 0.8074\n",
      "Epoch 471/500 | Train Loss: 0.2235 | Train Acc: 0.8704 | Val Loss: 0.7112 | Val Acc: 0.8593\n",
      "Epoch 472/500 | Train Loss: 0.2303 | Train Acc: 0.8815 | Val Loss: 0.6516 | Val Acc: 0.8148\n",
      "Epoch 473/500 | Train Loss: 0.2492 | Train Acc: 0.8685 | Val Loss: 0.7076 | Val Acc: 0.8074\n",
      "Epoch 474/500 | Train Loss: 0.2441 | Train Acc: 0.8833 | Val Loss: 0.6351 | Val Acc: 0.8000\n",
      "Epoch 475/500 | Train Loss: 0.2551 | Train Acc: 0.8537 | Val Loss: 0.5590 | Val Acc: 0.8074\n",
      "Epoch 476/500 | Train Loss: 0.2542 | Train Acc: 0.8333 | Val Loss: 0.7397 | Val Acc: 0.8519\n",
      "Epoch 477/500 | Train Loss: 0.2492 | Train Acc: 0.8611 | Val Loss: 0.6947 | Val Acc: 0.8074\n",
      "Epoch 478/500 | Train Loss: 0.2342 | Train Acc: 0.8667 | Val Loss: 0.7516 | Val Acc: 0.8074\n",
      "Epoch 479/500 | Train Loss: 0.2391 | Train Acc: 0.8667 | Val Loss: 0.7671 | Val Acc: 0.8222\n",
      "Epoch 480/500 | Train Loss: 0.2524 | Train Acc: 0.8685 | Val Loss: 0.7208 | Val Acc: 0.8148\n",
      "Epoch 481/500 | Train Loss: 0.2178 | Train Acc: 0.8630 | Val Loss: 0.7281 | Val Acc: 0.8296\n",
      "Epoch 482/500 | Train Loss: 0.2457 | Train Acc: 0.8574 | Val Loss: 0.7232 | Val Acc: 0.8667\n",
      "Epoch 483/500 | Train Loss: 0.2354 | Train Acc: 0.8704 | Val Loss: 0.6201 | Val Acc: 0.8074\n",
      "Epoch 484/500 | Train Loss: 0.2412 | Train Acc: 0.8611 | Val Loss: 0.6892 | Val Acc: 0.8074\n",
      "Epoch 485/500 | Train Loss: 0.2187 | Train Acc: 0.8722 | Val Loss: 0.6936 | Val Acc: 0.7852\n",
      "Epoch 486/500 | Train Loss: 0.2453 | Train Acc: 0.8685 | Val Loss: 0.6333 | Val Acc: 0.7704\n",
      "Epoch 487/500 | Train Loss: 0.2304 | Train Acc: 0.8667 | Val Loss: 0.6571 | Val Acc: 0.7926\n",
      "Epoch 488/500 | Train Loss: 0.2231 | Train Acc: 0.8926 | Val Loss: 0.8120 | Val Acc: 0.8444\n",
      "Epoch 489/500 | Train Loss: 0.2238 | Train Acc: 0.8889 | Val Loss: 0.6881 | Val Acc: 0.8370\n",
      "Epoch 490/500 | Train Loss: 0.2383 | Train Acc: 0.8759 | Val Loss: 0.7395 | Val Acc: 0.8000\n",
      "Epoch 491/500 | Train Loss: 0.2204 | Train Acc: 0.8741 | Val Loss: 0.8480 | Val Acc: 0.8370\n",
      "Epoch 492/500 | Train Loss: 0.2224 | Train Acc: 0.8796 | Val Loss: 0.7444 | Val Acc: 0.8667\n",
      "Epoch 493/500 | Train Loss: 0.2588 | Train Acc: 0.8426 | Val Loss: 0.6119 | Val Acc: 0.8148\n",
      "Epoch 494/500 | Train Loss: 0.2407 | Train Acc: 0.8630 | Val Loss: 0.7998 | Val Acc: 0.8444\n",
      "Epoch 495/500 | Train Loss: 0.2280 | Train Acc: 0.8741 | Val Loss: 0.7733 | Val Acc: 0.8222\n",
      "Epoch 496/500 | Train Loss: 0.2366 | Train Acc: 0.8722 | Val Loss: 0.6796 | Val Acc: 0.7852\n",
      "Epoch 497/500 | Train Loss: 0.2264 | Train Acc: 0.8963 | Val Loss: 0.6443 | Val Acc: 0.8074\n",
      "Epoch 498/500 | Train Loss: 0.2275 | Train Acc: 0.8833 | Val Loss: 0.6750 | Val Acc: 0.7926\n",
      "Epoch 499/500 | Train Loss: 0.2229 | Train Acc: 0.8685 | Val Loss: 0.7205 | Val Acc: 0.8000\n",
      "Epoch 500/500 | Train Loss: 0.2367 | Train Acc: 0.8685 | Val Loss: 0.6438 | Val Acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "from net.HybridGenomeNet import HybridGenomeNet\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "def train_hybrid():\n",
    "    train_loader,val_loader = get_train_val_dataloaders()\n",
    "    \n",
    "    device_string = \"cpu\"\n",
    "    if(torch.mps.is_available):\n",
    "        device_string = \"mps\"\n",
    "    elif torch.cuda.is_available():\n",
    "        device_string = \"cuda\"\n",
    "    \n",
    "    device = torch.device(device_string)\n",
    "    model = HybridGenomeNet().to(device)\n",
    "    class_weights = torch.tensor([2.0, 1.0]).to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
    "                                      T_0=10,  # Initial cycle length\n",
    "                                      T_mult=2,  # Cycle length multiplier\n",
    "                                      eta_min=1e-6)  # Minimum LR\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    num_epochs = 500\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            images = inputs[0].to(device)\n",
    "            sequences = inputs[1].to(device)\n",
    "            genes = inputs[2].to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model((images, sequences,genes))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                images = inputs[0].to(device)\n",
    "                sequences = inputs[1].to(device)\n",
    "                genes = inputs[2].to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model((images,sequences,genes))\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = train_loss / train_total\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        epoch_val_loss = val_loss / val_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | '\n",
    "              f'Train Loss: {epoch_train_loss:.4f} | '\n",
    "              f'Train Acc: {epoch_train_acc:.4f} | '\n",
    "              f'Val Loss: {epoch_val_loss:.4f} | '\n",
    "              f'Val Acc: {epoch_val_acc:.4f}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "train_hybrid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
